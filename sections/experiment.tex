\section{Experiment}

% This section is the meat of the paper
% This section should carefully describe the experiment and our analysis (design of the experiment)

Following this approach, we scraped the titles, icons, download figures, and first screenshots of 500 popular game apps that were recently released in the Android marketplace.  To gather our results, we built a site that asked subjects to select which app, in their opinion, had the highest likelihood of success through an iterative process that ended when the user decided to quit.  We released the survey to our friends on Facebook and our classmates on Piazza. Although the initial release included only the apps' names and icons, the subsequent version we propagated displayed screenshots. Moreover, the goal for the additional inclusion was to determine if incorporating screenshots could lead users to achieve more accurate predictions after our original results proved to be somewhat insignificant.  \\

Uniformly distributed binary-comparison trials were automated with server-side logic. We hypothesize that since people decide to download apps using relatively quick, perfunctory measures, crowds can provide reasonably good measures of app success when given an apps' icon, title, and screenshot. We also compared the accuracy of subjects' predictions with and without screenshots and confined parts of our analyses to subjects who completed at least ten contiguous rounds. Bias was a chief concern, so in order to counter bias due to varying degrees of experience with smartphone applications, we asked subjects to identify if they had seen the app before displaying the title and icon for fifteen seconds to the user. Because we were relying on attracting users solely through social media outlets, we decided to gamify our study to better incentivize these potential participants. With the promise of revealing our user's business acumen, we drew users as well with our slogan: â€œHow good is your entrepreneurial gut?"\\

For the crux of the study in which we had subjects compare apps, we asked subjects to choose the app they thought would be more successful.  Again, we wanted to ensure that participants who had knowledge of a particular app for a certain trial could not allow that knowledge to influence their decision. For that reason, we discarded trials in which users had self-reported prior knowledge of at least one app. For each given trial, due to past unhelpful or blank responses, we made our users' responses exceed five characters. Although we originally had subjects justify their selection after every trial, we quickly switched our justifications to approximately 20\% of trials in hopes of eliciting more meaningful responses.\\
